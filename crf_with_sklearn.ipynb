{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYDRnoJm16RH"
      },
      "source": [
        "https://github.com/Arlens26/Tokenizador_Y_Similaridad/blob/84fe73596e4e061d6bfcd43a231fd4af544c8f07/crf.py\n",
        "\n",
        "https://github.com/l11x0m7/book-of-qna-code/blob/17c218f754de14fee30d54ea36584e9e5c14f1e6/ch2/crf/crf_sample.py\n",
        "\n",
        "https://github.com/soroush-ziaeinejad/NLP_Course/blob/bae592ca012a77729c48b30720978148e584563d/ProposedMethod_ziaeines/src/CRF.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrTNcl7i9nvU",
        "outputId": "4d7c43a5-a8ae-465d-97e4-07213320a522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==0.22.2 in ./.local/lib/python3.8/site-packages (0.22.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in ./.local/lib/python3.8/site-packages (from scikit-learn==0.22.2) (1.9.1)\n",
            "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.8/site-packages (from scikit-learn==0.22.2) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.22.2) (1.22.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDnD8Ib4kwqv"
      },
      "source": [
        "## Exemplo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n5yUOFDHYmB"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP2d8PdSHYMJ",
        "outputId": "4aac8ec2-36f3-495b-e70d-bfffad49602d"
      },
      "outputs": [],
      "source": [
        "#!git clone -s https://github.com/mstauffer/tcdf_text_classification.git\n",
        "from tcdf_text_classification.iob_transformer import iob_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JEx5XHfHh8m",
        "outputId": "281b1c79-089b-4fca-efc0-462b1bf698ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/alilim/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BR1EuiLIHqnj"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BatlxWV2HjNz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-28 01:40:42.280516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-28 01:40:42.413644: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2022-11-28 01:40:42.442582: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-28 01:40:42.968523: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2022-11-28 01:40:42.968574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2022-11-28 01:40:42.968580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxqYjxU9mTcy"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yvRo8PSJmQ3L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('DODFCorpus_contratos_licitacoes_v2.csv')\n",
        "\n",
        "df = df.drop(['Unnamed: 0','Unnamed: 0.1'], axis =1)\n",
        "\n",
        "df['texto'] = df['texto'].str.replace(r'([A-Za-z]:)[0-9]', r'\\1 ', regex=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.query(\"tipo_rel == 'REL_EXTRATO_CONVENIO' | tipo_rel == 'REL_EXTRATO_CONTRATO'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VAFBf88cmXyr"
      },
      "outputs": [],
      "source": [
        "iob_v = iob_transformer('id_ato', 'texto', 'tipo_ent', keep_punctuation=True, return_df=False)\n",
        "\n",
        "acts, labels = iob_v.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags = set()\n",
        "\n",
        "for label in labels:\n",
        "    for tag in label:\n",
        "        tags.add(tag)\n",
        "tags = list(tags)\n",
        "tags_amt = len(tags)\n",
        "\n",
        "tags_amt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rr_fdxgSml-M"
      },
      "outputs": [],
      "source": [
        "def remove_wrong_tags(label_list):\n",
        "  for label in label_list:\n",
        "    for idx,w in enumerate(label):\n",
        "      if w in ['B-11','B-12','B-50']:\n",
        "        label[idx] = 'O'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Br2diXoTmmzZ"
      },
      "outputs": [],
      "source": [
        "remove_wrong_tags(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8JcUyyrClWPS"
      },
      "outputs": [],
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    \n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),        \n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "                \n",
        "    return features\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XXno94u6GFZ_"
      },
      "outputs": [],
      "source": [
        "inputs = [sent2features(s) for s in acts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pJbTzGdlMMt4"
      },
      "outputs": [],
      "source": [
        "targets = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from seqeval.metrics import f1_score, classification_report, precision_score, recall_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3943207/2053661115.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_train = np.array(inputs)[train.astype(int)]\n",
            "/tmp/ipykernel_3943207/2053661115.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_test = np.array(inputs)[test.astype(int)]\n",
            "/tmp/ipykernel_3943207/2053661115.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_train = np.array(targets)[train.astype(int)]\n",
            "/tmp/ipykernel_3943207/2053661115.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_test = np.array(targets)[test.astype(int)]\n",
            "loading training data to CRFsuite: 100%|██████████| 1412/1412 [00:02<00:00, 562.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 87343\n",
            "Seconds required: 0.484\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.421944\n",
            "c2: 0.044686\n",
            "num_memories: 6\n",
            "max_iterations: 70\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=3.48  loss=979333.40 active=86177 feature_norm=1.00\n",
            "Iter 2   time=6.98  loss=916419.13 active=85927 feature_norm=6.64\n",
            "Iter 3   time=1.69  loss=559496.60 active=81059 feature_norm=5.45\n",
            "Iter 4   time=16.77 loss=327749.96 active=84663 feature_norm=5.21\n",
            "Iter 5   time=10.57 loss=313691.47 active=83875 feature_norm=5.27\n",
            "Iter 6   time=5.23  loss=300273.38 active=83865 feature_norm=4.49\n",
            "Iter 7   time=1.74  loss=263350.35 active=72625 feature_norm=5.10\n",
            "Iter 8   time=5.33  loss=228567.76 active=72268 feature_norm=5.98\n",
            "Iter 9   time=7.15  loss=212785.43 active=72686 feature_norm=6.39\n",
            "Iter 10  time=3.58  loss=205569.31 active=73544 feature_norm=6.43\n",
            "Iter 11  time=1.78  loss=203079.50 active=73634 feature_norm=6.65\n",
            "Iter 12  time=1.79  loss=194528.59 active=73441 feature_norm=7.00\n",
            "Iter 13  time=1.74  loss=189622.27 active=73857 feature_norm=7.24\n",
            "Iter 14  time=1.74  loss=182701.60 active=73365 feature_norm=7.62\n",
            "Iter 15  time=1.73  loss=177362.98 active=73336 feature_norm=8.06\n",
            "Iter 16  time=1.77  loss=171203.60 active=73193 feature_norm=8.33\n",
            "Iter 17  time=1.79  loss=167781.61 active=73595 feature_norm=8.58\n",
            "Iter 18  time=1.74  loss=158719.99 active=72758 feature_norm=9.10\n",
            "Iter 19  time=1.73  loss=128822.62 active=71868 feature_norm=11.04\n",
            "Iter 20  time=1.81  loss=110549.06 active=69941 feature_norm=18.10\n",
            "Iter 21  time=1.74  loss=98436.49 active=72323 feature_norm=18.56\n",
            "Iter 22  time=1.74  loss=93058.59 active=72594 feature_norm=18.53\n",
            "Iter 23  time=1.77  loss=92118.77 active=72221 feature_norm=18.54\n",
            "Iter 24  time=1.79  loss=91292.99 active=72343 feature_norm=18.58\n",
            "Iter 25  time=1.74  loss=89580.39 active=71492 feature_norm=18.84\n",
            "Iter 26  time=1.75  loss=88266.12 active=71438 feature_norm=18.98\n",
            "Iter 27  time=1.74  loss=86656.67 active=70546 feature_norm=19.49\n",
            "Iter 28  time=1.74  loss=83968.20 active=70174 feature_norm=19.90\n",
            "Iter 29  time=1.76  loss=80066.03 active=67955 feature_norm=21.44\n",
            "Iter 30  time=1.78  loss=75766.43 active=66936 feature_norm=22.95\n",
            "Iter 31  time=1.75  loss=71860.23 active=66302 feature_norm=24.38\n",
            "Iter 32  time=1.74  loss=67571.95 active=66023 feature_norm=25.71\n",
            "Iter 33  time=1.73  loss=64499.60 active=66066 feature_norm=26.57\n",
            "Iter 34  time=1.73  loss=62120.26 active=65661 feature_norm=27.72\n",
            "Iter 35  time=1.74  loss=59787.47 active=65602 feature_norm=28.63\n",
            "Iter 36  time=1.74  loss=57803.88 active=65259 feature_norm=30.12\n",
            "Iter 37  time=1.76  loss=55157.59 active=65340 feature_norm=31.26\n",
            "Iter 38  time=1.76  loss=52542.75 active=65166 feature_norm=32.75\n",
            "Iter 39  time=3.49  loss=50961.13 active=65238 feature_norm=33.54\n",
            "Iter 40  time=3.47  loss=50495.27 active=65319 feature_norm=33.09\n",
            "Iter 41  time=1.74  loss=49290.78 active=64706 feature_norm=33.39\n",
            "Iter 42  time=1.80  loss=47183.36 active=63408 feature_norm=34.31\n",
            "Iter 43  time=1.77  loss=44277.01 active=62406 feature_norm=36.11\n",
            "Iter 44  time=1.78  loss=40714.14 active=61536 feature_norm=37.93\n",
            "Iter 45  time=1.78  loss=36580.46 active=58907 feature_norm=42.40\n",
            "Iter 46  time=1.78  loss=34922.32 active=57980 feature_norm=44.42\n",
            "Iter 47  time=1.79  loss=33308.59 active=57915 feature_norm=45.56\n",
            "Iter 48  time=1.78  loss=32119.21 active=57155 feature_norm=46.57\n",
            "Iter 49  time=3.60  loss=30504.90 active=56024 feature_norm=48.35\n",
            "Iter 50  time=7.14  loss=29888.69 active=55637 feature_norm=49.06\n",
            "Iter 51  time=7.14  loss=29595.59 active=55046 feature_norm=48.79\n",
            "Iter 52  time=3.48  loss=29339.73 active=54638 feature_norm=47.71\n",
            "Iter 53  time=1.74  loss=29246.67 active=54105 feature_norm=48.69\n",
            "Iter 54  time=1.74  loss=28820.00 active=54152 feature_norm=48.49\n",
            "Iter 55  time=1.78  loss=28535.41 active=53689 feature_norm=48.85\n",
            "Iter 56  time=1.77  loss=27914.12 active=52854 feature_norm=49.66\n",
            "Iter 57  time=1.78  loss=26525.99 active=49141 feature_norm=53.54\n",
            "Iter 58  time=1.78  loss=25744.47 active=48221 feature_norm=55.49\n",
            "Iter 59  time=1.76  loss=24617.12 active=45594 feature_norm=58.45\n",
            "Iter 60  time=1.75  loss=23595.78 active=42312 feature_norm=62.86\n",
            "Iter 61  time=1.75  loss=22969.00 active=43518 feature_norm=61.95\n",
            "Iter 62  time=1.76  loss=22314.98 active=42813 feature_norm=63.83\n",
            "Iter 63  time=1.75  loss=21236.64 active=41789 feature_norm=66.84\n",
            "Iter 64  time=1.79  loss=20472.56 active=40870 feature_norm=70.27\n",
            "Iter 65  time=1.80  loss=20166.17 active=40534 feature_norm=69.90\n",
            "Iter 66  time=1.79  loss=19655.24 active=40110 feature_norm=71.95\n",
            "Iter 67  time=3.58  loss=19118.72 active=39278 feature_norm=74.13\n",
            "Iter 68  time=1.79  loss=18288.02 active=37615 feature_norm=78.86\n",
            "Iter 69  time=1.79  loss=18018.43 active=36402 feature_norm=83.77\n",
            "Iter 70  time=1.80  loss=16813.00 active=36516 feature_norm=89.86\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 187.891\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 36516 (87343)\n",
            "Number of active attributes: 20510 (61717)\n",
            "Number of active labels: 50 (50)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.020\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alilim/.local/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "loading training data to CRFsuite: 100%|██████████| 1413/1413 [00:02<00:00, 545.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 89015\n",
            "Seconds required: 0.518\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.421944\n",
            "c2: 0.044686\n",
            "num_memories: 6\n",
            "max_iterations: 70\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=3.83  loss=999467.98 active=87800 feature_norm=1.00\n",
            "Iter 2   time=7.65  loss=947051.34 active=87539 feature_norm=6.80\n",
            "Iter 3   time=1.91  loss=575833.10 active=82706 feature_norm=5.58\n",
            "Iter 4   time=17.32 loss=347598.77 active=84636 feature_norm=5.33\n",
            "Iter 5   time=7.54  loss=347134.41 active=83872 feature_norm=4.84\n",
            "Iter 6   time=7.46  loss=305853.25 active=84560 feature_norm=4.46\n",
            "Iter 7   time=3.72  loss=303454.30 active=77696 feature_norm=5.83\n",
            "Iter 8   time=9.25  loss=298556.22 active=77846 feature_norm=5.91\n",
            "Iter 9   time=5.57  loss=290519.38 active=77976 feature_norm=5.82\n",
            "Iter 10  time=3.69  loss=287887.65 active=78780 feature_norm=5.71\n",
            "Iter 11  time=3.77  loss=278829.28 active=79108 feature_norm=5.59\n",
            "Iter 12  time=3.71  loss=275928.51 active=79090 feature_norm=5.48\n",
            "Iter 13  time=1.86  loss=274109.58 active=78838 feature_norm=5.34\n",
            "Iter 14  time=1.85  loss=263909.46 active=78752 feature_norm=5.25\n",
            "Iter 15  time=1.88  loss=262350.73 active=78497 feature_norm=5.18\n",
            "Iter 16  time=1.88  loss=259777.47 active=78322 feature_norm=5.15\n",
            "Iter 17  time=1.88  loss=257760.35 active=77866 feature_norm=5.15\n",
            "Iter 18  time=1.86  loss=222036.79 active=72284 feature_norm=5.87\n",
            "Iter 19  time=1.86  loss=203808.00 active=71884 feature_norm=6.58\n",
            "Iter 20  time=1.85  loss=192027.46 active=75412 feature_norm=6.74\n",
            "Iter 21  time=1.85  loss=191374.15 active=76849 feature_norm=7.28\n",
            "Iter 22  time=3.78  loss=177010.41 active=78137 feature_norm=7.57\n",
            "Iter 23  time=3.85  loss=175412.80 active=77991 feature_norm=7.51\n",
            "Iter 24  time=3.80  loss=168883.30 active=77381 feature_norm=7.82\n",
            "Iter 25  time=1.88  loss=163826.16 active=78033 feature_norm=8.09\n",
            "Iter 26  time=1.90  loss=159744.08 active=77436 feature_norm=8.39\n",
            "Iter 27  time=1.88  loss=156645.77 active=77485 feature_norm=8.49\n",
            "Iter 28  time=1.88  loss=152330.44 active=76620 feature_norm=8.86\n",
            "Iter 29  time=1.88  loss=146086.73 active=75909 feature_norm=9.54\n",
            "Iter 30  time=1.87  loss=134686.68 active=75096 feature_norm=10.70\n",
            "Iter 31  time=1.86  loss=118709.83 active=75812 feature_norm=11.57\n",
            "Iter 32  time=1.90  loss=114448.61 active=74860 feature_norm=13.36\n",
            "Iter 33  time=1.90  loss=98285.41 active=75295 feature_norm=14.43\n",
            "Iter 34  time=1.92  loss=92809.62 active=74713 feature_norm=15.74\n",
            "Iter 35  time=1.92  loss=87210.67 active=74803 feature_norm=16.46\n",
            "Iter 36  time=1.89  loss=83271.10 active=74268 feature_norm=17.76\n",
            "Iter 37  time=1.86  loss=76930.32 active=73703 feature_norm=19.50\n",
            "Iter 38  time=1.85  loss=72035.23 active=73293 feature_norm=21.92\n",
            "Iter 39  time=1.86  loss=67440.94 active=73018 feature_norm=23.23\n",
            "Iter 40  time=1.85  loss=61835.34 active=72097 feature_norm=25.31\n",
            "Iter 41  time=3.74  loss=57193.81 active=71314 feature_norm=26.90\n",
            "Iter 42  time=5.60  loss=56117.70 active=71113 feature_norm=27.43\n",
            "Iter 43  time=1.85  loss=55192.61 active=68190 feature_norm=28.13\n",
            "Iter 44  time=1.85  loss=52970.59 active=69234 feature_norm=28.45\n",
            "Iter 45  time=1.84  loss=50823.31 active=68238 feature_norm=29.76\n",
            "Iter 46  time=3.70  loss=50146.98 active=67924 feature_norm=30.30\n",
            "Iter 47  time=3.66  loss=47948.43 active=66025 feature_norm=32.15\n",
            "Iter 48  time=1.77  loss=44882.68 active=65159 feature_norm=33.98\n",
            "Iter 49  time=3.57  loss=44155.27 active=64386 feature_norm=35.38\n",
            "Iter 50  time=1.78  loss=41536.42 active=63363 feature_norm=37.00\n",
            "Iter 51  time=1.78  loss=39398.20 active=61752 feature_norm=39.74\n",
            "Iter 52  time=1.80  loss=37334.48 active=60716 feature_norm=42.36\n",
            "Iter 53  time=1.79  loss=35512.91 active=59443 feature_norm=45.14\n",
            "Iter 54  time=1.78  loss=34975.58 active=59492 feature_norm=45.71\n",
            "Iter 55  time=1.80  loss=34453.16 active=58215 feature_norm=46.86\n",
            "Iter 56  time=1.78  loss=32893.77 active=57887 feature_norm=48.19\n",
            "Iter 57  time=3.57  loss=32570.84 active=56739 feature_norm=50.43\n",
            "Iter 58  time=1.79  loss=30127.12 active=56162 feature_norm=53.65\n",
            "Iter 59  time=1.79  loss=28990.32 active=54819 feature_norm=56.36\n",
            "Iter 60  time=1.79  loss=28693.34 active=54848 feature_norm=55.38\n",
            "Iter 61  time=3.56  loss=28610.69 active=54987 feature_norm=55.85\n",
            "Iter 62  time=1.79  loss=28216.61 active=54943 feature_norm=56.03\n",
            "Iter 63  time=1.80  loss=28188.36 active=53746 feature_norm=57.42\n",
            "Iter 64  time=1.81  loss=27437.04 active=54042 feature_norm=57.23\n",
            "Iter 65  time=1.78  loss=27063.12 active=54233 feature_norm=57.68\n",
            "Iter 66  time=1.78  loss=26618.37 active=53437 feature_norm=58.25\n",
            "Iter 67  time=3.59  loss=25516.48 active=51662 feature_norm=60.22\n",
            "Iter 68  time=1.78  loss=25434.75 active=51038 feature_norm=62.40\n",
            "Iter 69  time=1.79  loss=24459.79 active=51143 feature_norm=61.74\n",
            "Iter 70  time=1.81  loss=24258.51 active=50898 feature_norm=62.20\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 204.250\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 50898 (89015)\n",
            "Number of active attributes: 30822 (62939)\n",
            "Number of active labels: 51 (51)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.025\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading training data to CRFsuite: 100%|██████████| 1413/1413 [00:02<00:00, 588.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 86642\n",
            "Seconds required: 0.460\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.421944\n",
            "c2: 0.044686\n",
            "num_memories: 6\n",
            "max_iterations: 70\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=3.37  loss=981390.63 active=85453 feature_norm=1.00\n",
            "Iter 2   time=6.76  loss=918798.21 active=85228 feature_norm=6.62\n",
            "Iter 3   time=1.69  loss=563599.05 active=80748 feature_norm=5.41\n",
            "Iter 4   time=15.28 loss=340504.12 active=84296 feature_norm=5.17\n",
            "Iter 5   time=10.22 loss=323919.04 active=80640 feature_norm=5.34\n",
            "Iter 6   time=6.74  loss=317587.49 active=82419 feature_norm=5.15\n",
            "Iter 7   time=6.76  loss=304529.68 active=82746 feature_norm=4.98\n",
            "Iter 8   time=6.80  loss=301022.46 active=82747 feature_norm=4.89\n",
            "Iter 9   time=5.06  loss=299714.93 active=82668 feature_norm=4.82\n",
            "Iter 10  time=1.69  loss=293820.14 active=79407 feature_norm=4.87\n",
            "Iter 11  time=1.69  loss=266993.87 active=74030 feature_norm=5.03\n",
            "Iter 12  time=3.39  loss=225671.08 active=72284 feature_norm=6.14\n",
            "Iter 13  time=1.69  loss=217720.23 active=73739 feature_norm=6.14\n",
            "Iter 14  time=1.69  loss=201448.75 active=73698 feature_norm=6.55\n",
            "Iter 15  time=1.69  loss=191703.70 active=73002 feature_norm=6.91\n",
            "Iter 16  time=3.37  loss=188103.67 active=71526 feature_norm=7.80\n",
            "Iter 17  time=1.71  loss=183602.07 active=73143 feature_norm=8.56\n",
            "Iter 18  time=1.70  loss=171352.06 active=73204 feature_norm=8.53\n",
            "Iter 19  time=5.06  loss=164584.76 active=72927 feature_norm=8.47\n",
            "Iter 20  time=1.69  loss=161953.22 active=73370 feature_norm=8.62\n",
            "Iter 21  time=1.69  loss=156750.72 active=72720 feature_norm=8.97\n",
            "Iter 22  time=1.69  loss=143092.95 active=71462 feature_norm=10.58\n",
            "Iter 23  time=1.69  loss=116638.09 active=71019 feature_norm=13.67\n",
            "Iter 24  time=1.69  loss=98837.46 active=72656 feature_norm=17.58\n",
            "Iter 25  time=1.69  loss=88119.15 active=71895 feature_norm=19.79\n",
            "Iter 26  time=1.69  loss=83413.41 active=72142 feature_norm=20.35\n",
            "Iter 27  time=1.69  loss=79910.11 active=71404 feature_norm=21.67\n",
            "Iter 28  time=1.69  loss=76298.40 active=71339 feature_norm=22.45\n",
            "Iter 29  time=1.69  loss=72150.58 active=70602 feature_norm=23.98\n",
            "Iter 30  time=1.69  loss=67702.79 active=70401 feature_norm=25.21\n",
            "Iter 31  time=1.69  loss=61377.76 active=69298 feature_norm=27.72\n",
            "Iter 32  time=1.69  loss=60175.20 active=68041 feature_norm=32.11\n",
            "Iter 33  time=1.68  loss=54617.83 active=68678 feature_norm=30.27\n",
            "Iter 34  time=1.69  loss=53972.17 active=67899 feature_norm=30.67\n",
            "Iter 35  time=1.69  loss=53219.79 active=68279 feature_norm=30.86\n",
            "Iter 36  time=1.69  loss=51571.23 active=67311 feature_norm=31.85\n",
            "Iter 37  time=1.69  loss=49193.41 active=66294 feature_norm=33.00\n",
            "Iter 38  time=3.38  loss=45734.83 active=64684 feature_norm=35.31\n",
            "Iter 39  time=6.82  loss=44949.39 active=64420 feature_norm=35.78\n",
            "Iter 40  time=1.72  loss=44874.39 active=63877 feature_norm=35.41\n",
            "Iter 41  time=1.69  loss=44111.03 active=63794 feature_norm=35.86\n",
            "Iter 42  time=1.69  loss=42952.47 active=62549 feature_norm=36.70\n",
            "Iter 43  time=1.69  loss=40879.21 active=59199 feature_norm=39.49\n",
            "Iter 44  time=1.69  loss=37412.82 active=56475 feature_norm=42.43\n",
            "Iter 45  time=1.69  loss=35402.56 active=54930 feature_norm=44.58\n",
            "Iter 46  time=1.69  loss=34239.58 active=53248 feature_norm=46.99\n",
            "Iter 47  time=1.69  loss=33727.75 active=53611 feature_norm=46.92\n",
            "Iter 48  time=1.69  loss=33506.25 active=53600 feature_norm=46.63\n",
            "Iter 49  time=1.69  loss=32795.08 active=52509 feature_norm=47.08\n",
            "Iter 50  time=1.69  loss=30817.10 active=51018 feature_norm=49.75\n",
            "Iter 51  time=1.69  loss=28808.76 active=49710 feature_norm=56.01\n",
            "Iter 52  time=1.69  loss=27879.58 active=50689 feature_norm=55.67\n",
            "Iter 53  time=3.37  loss=27529.35 active=50532 feature_norm=56.25\n",
            "Iter 54  time=1.69  loss=27113.87 active=50187 feature_norm=55.49\n",
            "Iter 55  time=5.07  loss=26890.79 active=49701 feature_norm=55.69\n",
            "Iter 56  time=1.72  loss=26257.82 active=49349 feature_norm=55.89\n",
            "Iter 57  time=1.69  loss=25225.93 active=47596 feature_norm=58.05\n",
            "Iter 58  time=1.70  loss=23996.23 active=46338 feature_norm=60.50\n",
            "Iter 59  time=1.69  loss=22710.37 active=44653 feature_norm=64.59\n",
            "Iter 60  time=1.69  loss=21866.70 active=44518 feature_norm=66.80\n",
            "Iter 61  time=1.70  loss=21088.35 active=43056 feature_norm=69.69\n",
            "Iter 62  time=1.71  loss=20306.03 active=41774 feature_norm=72.62\n",
            "Iter 63  time=1.69  loss=19535.44 active=40833 feature_norm=77.13\n",
            "Iter 64  time=1.69  loss=18957.60 active=39937 feature_norm=81.15\n",
            "Iter 65  time=1.69  loss=18372.71 active=40163 feature_norm=83.52\n",
            "Iter 66  time=1.69  loss=17780.13 active=39127 feature_norm=88.53\n",
            "Iter 67  time=1.69  loss=17240.55 active=39173 feature_norm=91.02\n",
            "Iter 68  time=1.69  loss=16887.18 active=38775 feature_norm=92.75\n",
            "Iter 69  time=1.69  loss=16641.88 active=37713 feature_norm=97.60\n",
            "Iter 70  time=1.69  loss=16078.35 active=37682 feature_norm=98.84\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 184.493\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 37682 (86642)\n",
            "Number of active attributes: 21000 (61174)\n",
            "Number of active labels: 50 (50)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.018\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading training data to CRFsuite: 100%|██████████| 1413/1413 [00:02<00:00, 580.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 87508\n",
            "Seconds required: 0.460\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.421944\n",
            "c2: 0.044686\n",
            "num_memories: 6\n",
            "max_iterations: 70\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=3.43  loss=993695.81 active=86317 feature_norm=1.00\n",
            "Iter 2   time=6.85  loss=940358.00 active=86061 feature_norm=6.78\n",
            "Iter 3   time=1.72  loss=568108.27 active=81282 feature_norm=5.57\n",
            "Iter 4   time=21.77 loss=330941.15 active=83863 feature_norm=5.33\n",
            "Iter 5   time=8.55  loss=321500.99 active=85287 feature_norm=5.12\n",
            "Iter 6   time=8.60  loss=307116.23 active=85895 feature_norm=4.97\n",
            "Iter 7   time=5.13  loss=303983.41 active=85521 feature_norm=4.66\n",
            "Iter 8   time=1.71  loss=284159.33 active=75987 feature_norm=4.96\n",
            "Iter 9   time=1.71  loss=245716.39 active=74103 feature_norm=7.04\n",
            "Iter 10  time=3.44  loss=229621.20 active=74148 feature_norm=7.24\n",
            "Iter 11  time=5.13  loss=215896.29 active=74464 feature_norm=6.98\n",
            "Iter 12  time=1.71  loss=200237.67 active=76557 feature_norm=7.04\n",
            "Iter 13  time=1.74  loss=193245.33 active=76309 feature_norm=7.29\n",
            "Iter 14  time=1.72  loss=186859.79 active=75361 feature_norm=7.57\n",
            "Iter 15  time=3.42  loss=175521.89 active=72842 feature_norm=8.50\n",
            "Iter 16  time=1.71  loss=169367.06 active=72829 feature_norm=9.18\n",
            "Iter 17  time=1.71  loss=162994.51 active=74185 feature_norm=9.25\n",
            "Iter 18  time=1.71  loss=159201.59 active=73945 feature_norm=9.52\n",
            "Iter 19  time=1.72  loss=150208.54 active=72081 feature_norm=11.42\n",
            "Iter 20  time=1.74  loss=127694.36 active=72552 feature_norm=13.41\n",
            "Iter 21  time=1.74  loss=117259.61 active=71795 feature_norm=16.26\n",
            "Iter 22  time=1.74  loss=99095.90 active=72617 feature_norm=19.49\n",
            "Iter 23  time=1.71  loss=91351.62 active=72087 feature_norm=22.26\n",
            "Iter 24  time=1.71  loss=83677.87 active=72671 feature_norm=23.02\n",
            "Iter 25  time=1.71  loss=81297.40 active=72296 feature_norm=23.69\n",
            "Iter 26  time=1.71  loss=76531.78 active=71900 feature_norm=25.31\n",
            "Iter 27  time=1.71  loss=72177.90 active=71715 feature_norm=26.74\n",
            "Iter 28  time=1.71  loss=67855.17 active=71270 feature_norm=27.98\n",
            "Iter 29  time=1.72  loss=62472.36 active=70104 feature_norm=30.18\n",
            "Iter 30  time=1.72  loss=56447.14 active=68605 feature_norm=34.99\n",
            "Iter 31  time=1.71  loss=51531.07 active=68220 feature_norm=37.32\n",
            "Iter 32  time=3.42  loss=50843.53 active=68280 feature_norm=35.70\n",
            "Iter 33  time=1.72  loss=49816.79 active=68019 feature_norm=36.00\n",
            "Iter 34  time=1.73  loss=48457.83 active=67568 feature_norm=35.98\n",
            "Iter 35  time=3.42  loss=45659.52 active=66011 feature_norm=37.13\n",
            "Iter 36  time=1.73  loss=42148.86 active=63968 feature_norm=39.01\n",
            "Iter 37  time=3.44  loss=41472.38 active=61514 feature_norm=40.96\n",
            "Iter 38  time=1.72  loss=35251.79 active=58917 feature_norm=45.98\n",
            "Iter 39  time=1.74  loss=33331.85 active=57943 feature_norm=47.96\n",
            "Iter 40  time=1.72  loss=31917.38 active=56155 feature_norm=50.02\n",
            "Iter 41  time=3.43  loss=30914.02 active=54766 feature_norm=51.66\n",
            "Iter 42  time=1.72  loss=28806.96 active=54150 feature_norm=54.79\n",
            "Iter 43  time=1.72  loss=27334.74 active=53496 feature_norm=57.45\n",
            "Iter 44  time=5.17  loss=26525.29 active=53359 feature_norm=58.69\n",
            "Iter 45  time=1.72  loss=26308.86 active=52689 feature_norm=57.57\n",
            "Iter 46  time=1.72  loss=25622.93 active=51655 feature_norm=57.58\n",
            "Iter 47  time=3.43  loss=25037.73 active=50693 feature_norm=58.84\n",
            "Iter 48  time=1.72  loss=24706.02 active=50265 feature_norm=59.57\n",
            "Iter 49  time=1.72  loss=24526.96 active=50037 feature_norm=59.98\n",
            "Iter 50  time=1.72  loss=23731.24 active=47741 feature_norm=62.93\n",
            "Iter 51  time=1.71  loss=22746.21 active=47225 feature_norm=65.27\n",
            "Iter 52  time=1.72  loss=21565.12 active=43155 feature_norm=72.11\n",
            "Iter 53  time=3.43  loss=20870.38 active=45192 feature_norm=73.27\n",
            "Iter 54  time=1.71  loss=20701.52 active=44091 feature_norm=71.50\n",
            "Iter 55  time=1.72  loss=20357.86 active=42821 feature_norm=73.80\n",
            "Iter 56  time=1.72  loss=19720.15 active=42692 feature_norm=75.15\n",
            "Iter 57  time=3.44  loss=19541.52 active=42397 feature_norm=76.13\n",
            "Iter 58  time=1.71  loss=19373.79 active=42152 feature_norm=75.64\n",
            "Iter 59  time=1.71  loss=19312.07 active=41509 feature_norm=76.36\n",
            "Iter 60  time=1.74  loss=19097.52 active=41816 feature_norm=76.33\n",
            "Iter 61  time=1.72  loss=18897.43 active=41238 feature_norm=76.90\n",
            "Iter 62  time=3.42  loss=18503.58 active=40279 feature_norm=78.78\n",
            "Iter 63  time=1.72  loss=18224.59 active=39372 feature_norm=82.94\n",
            "Iter 64  time=1.71  loss=17436.28 active=39502 feature_norm=85.15\n",
            "Iter 65  time=1.72  loss=17171.17 active=38595 feature_norm=87.37\n",
            "Iter 66  time=1.75  loss=16868.42 active=37558 feature_norm=90.17\n",
            "Iter 67  time=1.72  loss=16438.92 active=36828 feature_norm=93.24\n",
            "Iter 68  time=1.72  loss=16050.51 active=36406 feature_norm=95.94\n",
            "Iter 69  time=1.72  loss=15789.27 active=35871 feature_norm=98.58\n",
            "Iter 70  time=1.71  loss=15526.48 active=35333 feature_norm=101.49\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 188.329\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 35333 (87508)\n",
            "Number of active attributes: 19545 (61888)\n",
            "Number of active labels: 51 (51)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.018\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading training data to CRFsuite: 100%|██████████| 1413/1413 [00:02<00:00, 585.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 88630\n",
            "Seconds required: 0.456\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.421944\n",
            "c2: 0.044686\n",
            "num_memories: 6\n",
            "max_iterations: 70\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=3.45  loss=986292.06 active=87361 feature_norm=1.00\n",
            "Iter 2   time=6.95  loss=936175.10 active=87143 feature_norm=6.76\n",
            "Iter 3   time=1.75  loss=572013.90 active=82396 feature_norm=5.52\n",
            "Iter 4   time=22.33 loss=316865.23 active=84754 feature_norm=5.26\n",
            "Iter 5   time=10.36 loss=315477.65 active=85490 feature_norm=5.18\n",
            "Iter 6   time=8.63  loss=310959.56 active=85816 feature_norm=5.06\n",
            "Iter 7   time=6.95  loss=310933.16 active=85957 feature_norm=4.91\n",
            "Iter 8   time=5.24  loss=310348.62 active=85947 feature_norm=4.69\n",
            "Iter 9   time=1.77  loss=298494.11 active=83456 feature_norm=4.68\n",
            "Iter 10  time=1.74  loss=296102.53 active=81443 feature_norm=4.67\n",
            "Iter 11  time=1.74  loss=279311.42 active=74921 feature_norm=4.88\n",
            "Iter 12  time=1.73  loss=240864.01 active=75276 feature_norm=5.50\n",
            "Iter 13  time=5.18  loss=225783.01 active=74618 feature_norm=6.07\n",
            "Iter 14  time=1.73  loss=213850.09 active=75509 feature_norm=6.17\n",
            "Iter 15  time=1.73  loss=204242.70 active=74995 feature_norm=6.47\n",
            "Iter 16  time=3.45  loss=195502.52 active=75119 feature_norm=7.13\n",
            "Iter 17  time=1.73  loss=179270.91 active=74318 feature_norm=7.54\n",
            "Iter 18  time=1.73  loss=172853.48 active=74427 feature_norm=7.91\n",
            "Iter 19  time=1.73  loss=167033.59 active=74099 feature_norm=8.60\n",
            "Iter 20  time=1.73  loss=161792.68 active=75093 feature_norm=8.65\n",
            "Iter 21  time=1.73  loss=160396.04 active=75088 feature_norm=8.72\n",
            "Iter 22  time=1.73  loss=153145.54 active=74137 feature_norm=9.13\n",
            "Iter 23  time=1.73  loss=135408.98 active=71997 feature_norm=11.19\n",
            "Iter 24  time=3.48  loss=114676.07 active=71804 feature_norm=13.03\n",
            "Iter 25  time=1.74  loss=105357.96 active=71545 feature_norm=14.30\n",
            "Iter 26  time=1.75  loss=97050.76 active=72643 feature_norm=15.45\n",
            "Iter 27  time=1.75  loss=91715.45 active=72183 feature_norm=16.51\n",
            "Iter 28  time=1.74  loss=85963.45 active=71934 feature_norm=17.56\n",
            "Iter 29  time=1.74  loss=79331.40 active=69072 feature_norm=21.37\n",
            "Iter 30  time=1.74  loss=71412.57 active=69808 feature_norm=22.65\n",
            "Iter 31  time=1.76  loss=68477.03 active=69776 feature_norm=23.20\n",
            "Iter 32  time=1.76  loss=61824.75 active=66987 feature_norm=25.99\n",
            "Iter 33  time=1.73  loss=61093.28 active=65800 feature_norm=27.55\n",
            "Iter 34  time=1.73  loss=57530.63 active=67738 feature_norm=25.34\n",
            "Iter 35  time=3.50  loss=56441.96 active=67780 feature_norm=25.91\n",
            "Iter 36  time=1.74  loss=55408.22 active=66568 feature_norm=26.22\n",
            "Iter 37  time=1.76  loss=53993.59 active=61777 feature_norm=28.35\n",
            "Iter 38  time=1.73  loss=50897.56 active=62409 feature_norm=28.98\n",
            "Iter 39  time=1.73  loss=48813.05 active=62747 feature_norm=29.34\n",
            "Iter 40  time=3.46  loss=47356.21 active=61630 feature_norm=29.98\n",
            "Iter 41  time=1.73  loss=45713.57 active=59515 feature_norm=30.48\n",
            "Iter 42  time=3.49  loss=43827.72 active=59022 feature_norm=31.55\n",
            "Iter 43  time=1.73  loss=40511.33 active=56762 feature_norm=34.16\n",
            "Iter 44  time=1.73  loss=37316.20 active=54993 feature_norm=38.07\n",
            "Iter 45  time=1.73  loss=34293.14 active=54630 feature_norm=42.28\n",
            "Iter 46  time=1.73  loss=33459.88 active=54225 feature_norm=43.20\n",
            "Iter 47  time=3.47  loss=31755.82 active=52996 feature_norm=46.01\n",
            "Iter 48  time=1.74  loss=29870.18 active=52802 feature_norm=49.61\n",
            "Iter 49  time=3.48  loss=28537.71 active=53169 feature_norm=51.25\n",
            "Iter 50  time=1.73  loss=28142.78 active=52595 feature_norm=51.36\n",
            "Iter 51  time=1.74  loss=27127.57 active=51849 feature_norm=53.55\n",
            "Iter 52  time=3.48  loss=26088.43 active=51463 feature_norm=55.60\n",
            "Iter 53  time=1.74  loss=25615.37 active=51189 feature_norm=56.49\n",
            "Iter 54  time=1.73  loss=24253.86 active=49252 feature_norm=62.24\n",
            "Iter 55  time=1.74  loss=23258.10 active=48870 feature_norm=64.71\n",
            "Iter 56  time=1.74  loss=22378.20 active=47812 feature_norm=67.68\n",
            "Iter 57  time=3.46  loss=21907.82 active=47216 feature_norm=69.33\n",
            "Iter 58  time=1.73  loss=21311.92 active=46173 feature_norm=69.48\n",
            "Iter 59  time=1.74  loss=20482.74 active=43995 feature_norm=73.63\n",
            "Iter 60  time=1.73  loss=20150.87 active=44221 feature_norm=73.06\n",
            "Iter 61  time=1.73  loss=19774.45 active=43733 feature_norm=74.43\n",
            "Iter 62  time=1.73  loss=19355.00 active=41190 feature_norm=82.17\n",
            "Iter 63  time=1.75  loss=18441.95 active=43024 feature_norm=83.67\n",
            "Iter 64  time=1.76  loss=18106.07 active=41916 feature_norm=85.55\n",
            "Iter 65  time=3.46  loss=17796.19 active=38727 feature_norm=85.28\n",
            "Iter 66  time=1.73  loss=17249.16 active=38259 feature_norm=92.25\n",
            "Iter 67  time=1.74  loss=16924.90 active=38881 feature_norm=91.66\n",
            "Iter 68  time=1.73  loss=16744.42 active=38323 feature_norm=92.80\n",
            "Iter 69  time=1.74  loss=16421.71 active=37541 feature_norm=95.51\n",
            "Iter 70  time=1.75  loss=16119.06 active=36405 feature_norm=101.15\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 194.185\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 36405 (88630)\n",
            "Number of active attributes: 19979 (62170)\n",
            "Number of active labels: 51 (51)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.020\n",
            "\n"
          ]
        }
      ],
      "source": [
        "f1 = []\n",
        "acc = []\n",
        "reps = []\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "    from sklearn_crfsuite import CRF\n",
        "\n",
        "    x_train = np.array(inputs)[train.astype(int)]\n",
        "    x_test = np.array(inputs)[test.astype(int)]\n",
        "\n",
        "    y_train = np.array(targets)[train.astype(int)]\n",
        "    y_test = np.array(targets)[test.astype(int)]\n",
        "\n",
        "    crf = CRF(\n",
        "    algorithm='lbfgs', \n",
        "    c1=0.42194423530178, \n",
        "    c2=0.044686453706365134, \n",
        "    max_iterations=70, \n",
        "    all_possible_transitions=True, verbose=1)\n",
        "\n",
        "    crf.fit(X=x_train, y=y_train)\n",
        "\n",
        "    y_pred = crf.predict(x_test)\n",
        "\n",
        "    f1.append(f1_score(y_test, y_pred))\n",
        "\n",
        "    reps.append(classification_report(y_test,y_pred))\n",
        "\n",
        "    acc.append(accuracy_score(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.8154056517775752,\n",
              " 0.7757211538461538,\n",
              " 0.8178070898598516,\n",
              " 0.8170426065162907,\n",
              " 0.8385308385308385]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8129014681061421"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.02042902584471683"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.std(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "cnpj_entidade_contratada       0.74      0.66      0.70        99\n",
            "cnpj_entidade_convenente       0.00      0.00      0.00         2\n",
            "   cnpj_orgao_concedente       0.00      0.00      0.00         3\n",
            "  cnpj_orgao_contratante       0.83      0.63      0.72        30\n",
            "            codigo_siggo       0.74      0.78      0.76        40\n",
            "data_assinatura_contrato       0.72      0.85      0.78       243\n",
            "data_assinatura_convenio       0.00      0.00      0.00         8\n",
            "     entidade_contratada       0.79      0.69      0.74       369\n",
            "     entidade_convenente       0.00      0.00      0.00        11\n",
            "           fonte_recurso       0.98      0.89      0.93       296\n",
            "        natureza_despesa       0.89      0.85      0.87       244\n",
            "        nome_responsavel       0.94      0.69      0.79        42\n",
            "            nota_empenho       0.92      0.79      0.85       281\n",
            "         numero_contrato       0.86      0.90      0.88       367\n",
            "         numero_convenio       0.00      0.00      0.00         6\n",
            "         objeto_contrato       0.69      0.68      0.69       351\n",
            "         objeto_convenio       0.00      0.00      0.00         8\n",
            "        orgao_concedente       0.00      0.00      0.00         5\n",
            "       orgao_contratante       0.81      0.85      0.83       452\n",
            "            processo_gdf       0.82      0.86      0.84       340\n",
            "       programa_trabalho       0.89      0.86      0.88       252\n",
            "    unidade_orcamentaria       0.95      0.93      0.94       188\n",
            "          valor_contrato       0.79      0.86      0.83       407\n",
            "          valor_convenio       0.00      0.00      0.00         4\n",
            "       vigencia_contrato       0.77      0.78      0.78       375\n",
            "       vigencia_convenio       1.00      0.17      0.29         6\n",
            "\n",
            "               micro avg       0.82      0.81      0.82      4429\n",
            "               macro avg       0.58      0.53      0.54      4429\n",
            "            weighted avg       0.82      0.81      0.81      4429\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "cnpj_entidade_contratada       0.96      0.25      0.40       102\n",
            "cnpj_entidade_convenente       0.00      0.00      0.00         3\n",
            "  cnpj_orgao_contratante       1.00      0.15      0.26        27\n",
            "            codigo_siggo       0.81      0.45      0.58        29\n",
            "data_assinatura_contrato       0.64      0.85      0.73       220\n",
            "data_assinatura_convenio       0.00      0.00      0.00        12\n",
            "     entidade_contratada       0.75      0.65      0.70       349\n",
            "     entidade_convenente       0.00      0.00      0.00         8\n",
            "           fonte_recurso       0.95      0.86      0.90       280\n",
            "        natureza_despesa       0.93      0.78      0.85       245\n",
            "        nome_responsavel       1.00      0.90      0.95        39\n",
            "            nota_empenho       0.89      0.65      0.75       263\n",
            "         numero_contrato       0.89      0.87      0.88       382\n",
            "         numero_convenio       0.00      0.00      0.00         3\n",
            "         objeto_contrato       0.70      0.67      0.68       348\n",
            "         objeto_convenio       0.00      0.00      0.00         9\n",
            "        orgao_concedente       0.00      0.00      0.00         3\n",
            "       orgao_contratante       0.82      0.75      0.79       469\n",
            "            processo_gdf       0.81      0.81      0.81       347\n",
            "       programa_trabalho       0.88      0.57      0.69       244\n",
            "    unidade_orcamentaria       0.88      0.81      0.84       165\n",
            "          valor_contrato       0.78      0.91      0.84       404\n",
            "          valor_convenio       0.00      0.00      0.00         3\n",
            "       vigencia_contrato       0.78      0.76      0.77       383\n",
            "       vigencia_convenio       0.00      0.00      0.00         9\n",
            "\n",
            "               micro avg       0.81      0.74      0.78      4346\n",
            "               macro avg       0.58      0.47      0.50      4346\n",
            "            weighted avg       0.81      0.74      0.77      4346\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "cnpj_entidade_contratada       0.85      0.64      0.73        83\n",
            "cnpj_entidade_convenente       0.00      0.00      0.00         4\n",
            "   cnpj_orgao_concedente       0.00      0.00      0.00         2\n",
            "  cnpj_orgao_contratante       0.94      0.71      0.81        21\n",
            "            codigo_siggo       0.79      0.79      0.79        29\n",
            "data_assinatura_contrato       0.71      0.86      0.78       236\n",
            "data_assinatura_convenio       0.00      0.00      0.00         8\n",
            "     entidade_contratada       0.79      0.71      0.75       346\n",
            "     entidade_convenente       0.00      0.00      0.00        10\n",
            "           fonte_recurso       0.96      0.89      0.93       288\n",
            "        natureza_despesa       0.95      0.87      0.91       236\n",
            "        nome_responsavel       0.97      0.87      0.92        38\n",
            "            nota_empenho       0.97      0.75      0.84       283\n",
            "         numero_contrato       0.88      0.90      0.89       368\n",
            "         numero_convenio       0.00      0.00      0.00         7\n",
            "         objeto_contrato       0.69      0.69      0.69       343\n",
            "         objeto_convenio       0.33      0.10      0.15        10\n",
            "        orgao_concedente       0.00      0.00      0.00         6\n",
            "       orgao_contratante       0.83      0.88      0.85       435\n",
            "            processo_gdf       0.83      0.86      0.84       346\n",
            "       programa_trabalho       0.88      0.79      0.83       241\n",
            "    unidade_orcamentaria       0.92      0.87      0.90       181\n",
            "          valor_contrato       0.78      0.89      0.83       403\n",
            "          valor_convenio       0.00      0.00      0.00         4\n",
            "       vigencia_contrato       0.74      0.74      0.74       364\n",
            "       vigencia_convenio       0.00      0.00      0.00         6\n",
            "\n",
            "               micro avg       0.83      0.81      0.82      4298\n",
            "               macro avg       0.57      0.53      0.55      4298\n",
            "            weighted avg       0.82      0.81      0.81      4298\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "cnpj_entidade_contratada       0.87      0.61      0.72       108\n",
            "cnpj_entidade_convenente       0.00      0.00      0.00         2\n",
            "  cnpj_orgao_contratante       0.88      0.64      0.74        33\n",
            "            codigo_siggo       0.71      0.63      0.67        38\n",
            "data_assinatura_contrato       0.86      0.72      0.79       235\n",
            "data_assinatura_convenio       0.00      0.00      0.00         5\n",
            "     entidade_contratada       0.84      0.68      0.76       359\n",
            "     entidade_convenente       0.00      0.00      0.00         7\n",
            "           fonte_recurso       0.95      0.92      0.93       272\n",
            "        natureza_despesa       0.89      0.85      0.87       219\n",
            "        nome_responsavel       0.97      0.76      0.85        41\n",
            "            nota_empenho       0.94      0.69      0.79       268\n",
            "         numero_contrato       0.88      0.87      0.87       388\n",
            "         numero_convenio       0.00      0.00      0.00         6\n",
            "         objeto_contrato       0.70      0.70      0.70       350\n",
            "         objeto_convenio       0.50      0.20      0.29         5\n",
            "        orgao_concedente       0.00      0.00      0.00         3\n",
            "       orgao_contratante       0.87      0.85      0.86       464\n",
            "            processo_gdf       0.84      0.88      0.86       338\n",
            "       programa_trabalho       0.88      0.78      0.82       236\n",
            "    unidade_orcamentaria       0.85      0.90      0.87       156\n",
            "          valor_contrato       0.76      0.91      0.83       397\n",
            "          valor_convenio       0.00      0.00      0.00         3\n",
            "       vigencia_contrato       0.80      0.79      0.79       368\n",
            "       vigencia_convenio       0.50      0.20      0.29         5\n",
            "\n",
            "               micro avg       0.84      0.79      0.82      4306\n",
            "               macro avg       0.62      0.54      0.57      4306\n",
            "            weighted avg       0.84      0.79      0.81      4306\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "cnpj_entidade_contratada       0.94      0.66      0.78        89\n",
            "cnpj_entidade_convenente       0.00      0.00      0.00         1\n",
            "  cnpj_orgao_contratante       0.76      0.83      0.79        23\n",
            "            codigo_siggo       0.85      0.64      0.73        36\n",
            "data_assinatura_contrato       0.75      0.82      0.79       228\n",
            "data_assinatura_convenio       0.00      0.00      0.00         1\n",
            "     entidade_contratada       0.82      0.72      0.77       350\n",
            "     entidade_convenente       0.50      0.50      0.50         4\n",
            "           fonte_recurso       0.97      0.89      0.92       297\n",
            "        natureza_despesa       0.95      0.86      0.90       254\n",
            "        nome_responsavel       0.98      0.89      0.93        46\n",
            "            nota_empenho       0.99      0.74      0.84       298\n",
            "         numero_contrato       0.90      0.91      0.90       381\n",
            "         numero_convenio       0.00      0.00      0.00         3\n",
            "         objeto_contrato       0.71      0.66      0.68       347\n",
            "         objeto_convenio       0.00      0.00      0.00         2\n",
            "        orgao_concedente       0.00      0.00      0.00         4\n",
            "       orgao_contratante       0.88      0.86      0.87       472\n",
            "            processo_gdf       0.87      0.89      0.88       341\n",
            "       programa_trabalho       0.90      0.82      0.86       261\n",
            "    unidade_orcamentaria       0.96      0.90      0.93       181\n",
            "          valor_contrato       0.79      0.91      0.85       423\n",
            "          valor_convenio       0.00      0.00      0.00         1\n",
            "       vigencia_contrato       0.80      0.78      0.79       384\n",
            "       vigencia_convenio       1.00      0.33      0.50         3\n",
            "\n",
            "               micro avg       0.86      0.82      0.84      4430\n",
            "               macro avg       0.65      0.58      0.61      4430\n",
            "            weighted avg       0.86      0.82      0.84      4430\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(reps[0])\n",
        "print(reps[1])\n",
        "print(reps[2])\n",
        "print(reps[3])\n",
        "print(reps[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Valores do kfold (contratos e aditamentos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# avaliação nos extratos de contrato\n",
        "\n",
        "#np.mean(f1)\n",
        "# 0.8659178331585456\n",
        "\n",
        "#np.std(f1)\n",
        "#0.00676026225068485\n",
        "\n",
        "#f1 \n",
        "# [0.8724496511780966,\n",
        "#  0.8605144523998941,\n",
        "#  0.8555481727574752,\n",
        "#  0.8723293381969777,\n",
        "#  0.8687475512602846]\n",
        "\n",
        "#acc\n",
        "# [0.9655420835145716,\n",
        "#  0.9584223925503383,\n",
        "#  0.9588658202500313,\n",
        "#  0.964885026101804,\n",
        "#  0.9619780829518657]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# avaliação nos aditamentos\n",
        "\n",
        "#np.mean(f1)\n",
        "# 0.8103676653053375\n",
        "\n",
        "#np.std(f1)\n",
        "#0.01321410709546104\n",
        "\n",
        "#f1 \n",
        "# [0.8037572988068037,\n",
        "#  0.8195469585136168,\n",
        "#  0.8264504687104129,\n",
        "#  0.813541933829187,\n",
        "#  0.7885416666666667]\n",
        "\n",
        "#acc\n",
        "# [0.9419161589998118,\n",
        "#  0.9285171627874853,\n",
        "#  0.9467657211466306,\n",
        "#  0.9436907582938389,\n",
        "#  0.9197376733551939]\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
